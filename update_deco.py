import json
import requests
import time
import re
import urllib3
from concurrent.futures import ThreadPoolExecutor

# ç¦ç”¨å®‰å…¨è¯·æ±‚è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ================= é…ç½®åŒº =================

# 1. æ ¸å¿ƒæºï¼šä¸‡å…†/4K/CDN é‡å‹èŠ‚ç‚¹ (å¼ºåˆ¶ä¿ç•™ï¼Œé™¤éå½»åº•æ— æ³•è®¿é—®)
CORE_SITES = [
    {"id": "sn_4k", "name": "ğŸ’ ç´¢å°¼Â·4Ké¡¶çº§é‡‡é›†", "api": "https://suoniapi.com/api.php/provide/vod"},
    {"id": "k4_zy", "name": "ğŸš€ æœ€å¤§Â·4Kç‰¹çº¿", "api": "https://api.zuidapi.com/api.php/provide/vod"},
    {"id": "lz_4k", "name": "âš¡ é‡å­Â·éª¨å¹²åŠ é€Ÿ", "api": "https://cj.lziapi.com/api.php/provide/vod"},
    {"id": "gs_zy", "name": "ğŸš€ å…‰é€ŸÂ·ä¸‡å…†å“åº”", "api": "https://api.guangsuapi.com/api.php/provide/vod"},
    {"id": "yz_hd", "name": "ğŸ”¥ ä¼˜è´¨Â·è“å…‰/1080P", "api": "https://api.yzzy-api.com/inc/apijson.php/provide/vod"},
    {"id": "sd_zy", "name": "ğŸ“¡ é—ªç”µÂ·é«˜é¢‘å®½ç›´è¿", "api": "https://sdzyapi.com/api.php/provide/vod"},
    {"id": "bf_cdn", "name": "ğŸŒªï¸ æš´é£Â·CDNå…¨èŠ‚ç‚¹", "api": "https://bfzyapi.com/api.php/provide/vod"},
    {"id": "yh_dm", "name": "ğŸŒ¸ æ¨±èŠ±Â·åŠ¨æ¼«ä¸“çº¿", "api": "https://m3u8.apiyhzy.com/api.php/provide/vod"},
    {"id": "db_zy", "name": "ğŸ¬ è±†ç“£Â·é«˜åˆ†æ¦œå•", "api": "https://caiji.dbzy.tv/api.php/provide/vod"},
    {"id": "mt_zy", "name": "ğŸ¶ èŒ…å°Â·ç²¾å“èµ„æº", "api": "https://www.maotaizy.com/api.php/provide/vod/"}
]

# 2. æ™ºèƒ½æœé›†æºï¼šè‡ªåŠ¨ä»ä»¥ä¸‹ä»“åº“çˆ¬å–æœ€æ–°æ¥å£
CRAWL_SOURCES = [
    "https://raw.githubusercontent.com/gaotianliuyun/gao/master/0827.json",
    "https://raw.githubusercontent.com/FongMi/TV/release/lean.json",
    "https://raw.githubusercontent.com/yydsys/yydsys.github.io/master/yydsys.json",
    "http://itvbox.cc/tvbox/meow.json"
]

OUTPUT_FILE = "deco.json"
TIMEOUT = 15       # æ ¸å¿ƒæºå®½é™åˆ°15ç§’ï¼Œç¡®ä¿é‡å‹èŠ‚ç‚¹èƒ½æ¡æ‰‹
MAX_WORKERS = 20   # æé«˜å¹¶å‘æ•°ï¼ŒåŠ å¿«å…¨ç½‘æœé›†é€Ÿåº¦

# ================= é€»è¾‘åŒº =================

def fetch_external_apis():
    """æ™ºèƒ½çˆ¬å–å…¨ç½‘æ¥å£åœ°å€"""
    print("ğŸŒ æ­£åœ¨æ‰§è¡Œå…¨ç½‘æœé›†...")
    collected = set()
    for url in CRAWL_SOURCES:
        try:
            r = requests.get(url, timeout=10, verify=False)
            # åŒ¹é…æ‰€æœ‰è‹¹æœCMSæ ‡å‡†APIæ ¼å¼
            links = re.findall(r'https?://[^\s"\'\[\]]+\/api\.php\/provide\/vod', r.text)
            for link in links:
                collected.add(link)
        except:
            continue
    return list(collected)

def verify_api(api_url):
    """æµ‹è¯•æ¥å£å­˜æ´»çŠ¶æ€"""
    try:
        # é‡å‹æºå¯èƒ½å»¶è¿Ÿé«˜ï¼Œæˆ‘ä»¬ä¸»è¦çœ‹æ˜¯å¦èƒ½è¿é€š
        r = requests.get(api_url, timeout=TIMEOUT, verify=False)
        if r.status_code == 200 and ("list" in r.text or "vod" in r.text):
            return api_url
    except:
        return None

def check_and_build():
    valid_api_site = {}
    
    # --- æ­¥éª¤ 1ï¼šå¤„ç†æ ¸å¿ƒé‡å‹æº ---
    print(f"ğŸ“¡ æ­£åœ¨éªŒè¯æ ¸å¿ƒé‡å‹æº (ä¸‡å…†/4K/CDN)...")
    for site in CORE_SITES:
        if verify_api(site["api"]):
            print(f"âœ… [æ ¸å¿ƒ] {site['name']} æ­£å¸¸")
            valid_api_site[site["id"]] = {
                "api": site["api"],
                "name": site["name"],
                "detail": site["api"].split("/api.php")[0]
            }
        else:
            print(f"âŒ [æ ¸å¿ƒ] {site['name']} æš‚æ—¶ç¦»çº¿")

    # --- æ­¥éª¤ 2ï¼šå…¨ç½‘æ™ºèƒ½æœé›†è¡¥å…… ---
    external_links = fetch_external_apis()
    print(f"ğŸ” å‘ç° {len(external_links)} ä¸ªå¤–éƒ¨æ¥å£ï¼Œå¼€å§‹æ™ºèƒ½ç­›é€‰...")
    
    # æ’é™¤æ‰æ ¸å¿ƒæºä¸­å·²æœ‰çš„åœ°å€
    core_apis = [s["api"] for s in CORE_SITES]
    fresh_links = [l for l in external_links if l not in core_apis]

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        results = list(executor.map(verify_api, fresh_links))
        
    # å°†æœé›†åˆ°çš„æœ‰æ•ˆæºåŠ å…¥ï¼Œå–å‰20ä¸ª
    added_count = 0
    for link in results:
        if link:
            site_id = f"auto_{added_count}"
            valid_api_site[site_id] = {
                "api": link,
                "name": f"ğŸ¤– æ™ºèƒ½æº_{added_count+1:02d}",
                "detail": link.split("/api.php")[0]
            }
            added_count += 1
            if added_count >= 20: break

    # --- æ­¥éª¤ 3ï¼šæ„é€ ç¬¦åˆ DecoTV çš„åµŒå¥— JSON ---
    final_json = {
        "cache_time": 9200,
        "api_site": valid_api_site,
        "custom_category": [
            {"name": "ğŸï¸ 4KÂ·é«˜ç ç‡é‡å‹åŒº", "type": "movie", "query": "4K"},
            {"name": "ğŸ¿ NetflixÂ·ä¸“åŒº", "type": "movie", "query": "ç½‘é£"},
            {"name": "ğŸ§§ åè¯­Â·å¹´åº¦ç²¾é€‰", "type": "movie", "query": "åè¯­"},
            {"name": "ğŸ± 2026Â·åŠ¨æ¼«æ–°ç•ª", "type": "anime", "query": "2026"}
        ]
    }

    # å†™å…¥æ–‡ä»¶
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(final_json, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ¨ æ›´æ–°å®Œæˆï¼æ€»è®¡ä¿ç•™ {len(valid_api_site)} ä¸ªæºï¼Œå·²æŒ‰ DecoTV æ ¼å¼å¯¼å‡ºã€‚")

if __name__ == "__main__":
    check_and_build()
